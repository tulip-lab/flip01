{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (04) Math Foundation\n",
    "\n",
    "---\n",
    "Team Director: Ye Lei | ylei@tulip.academy<br />\n",
    "\n",
    "TULIP Academy <br />\n",
    "http://www.tulip.academy\n",
    "\n",
    "---\n",
    "\n",
    "## Session 12  Eigendecomposition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors and Eigenvalues\n",
    "\n",
    "First recall that an eigenvector of a matrix *$A$* is a non-zero vector *$v$* such that\n",
    "\n",
    "<center>*$Av=λv$*</center>\n",
    "\n",
    "for some scalar *$λ$*\n",
    "\n",
    "The value *$λ$*\n",
    "is called an eigenvalue of *$A$* .\n",
    "\n",
    "If an *$n×n$*\n",
    "matrix *$A$*  has *$n $* linearly independent eigenvectors, then *$A$* \n",
    "\n",
    "may be decomposed in the following manner:\n",
    "\n",
    "<center>*$A=BΛB$*<sup>$−1$</sup></center>\n",
    "\n",
    "where *$Λ$*  is a diagonal matrix whose diagonal entries are the eigenvalues of *$A $* and the columns of  *$ B $*  are the corresponding eigenvectors of *$ A$* .\n",
    "\n",
    "Facts:\n",
    "\n",
    "*  An $ n×n$ matrix is diagonizable ⟺ it has $n$ linearly independent eigenvectors.\n",
    "\n",
    "*   A symmetric, positive definite matrix has only positive eigenvalues and its eigendecomposition\n",
    "\n",
    "<center>*$A=BΛB$*<sup>$−1$</sup></center>\n",
    "\n",
    "is via an orthogonal transformation *$ B $* . (I.e. its eigenvectors are an orthonormal set)\n",
    "\n",
    "\n",
    "####  Calculating Eigenvalues\n",
    "\n",
    "It is easy to see from the definition that if *$v$* is an eigenvector of an *$n×n$* matrix *$A$* with eigenvalue *$λ$*, then\n",
    "\n",
    "<center>$Av−λI=0$</center>\n",
    "\n",
    "where *$I$*  is the identity matrix of dimension n and *$0$* is an n-dimensional zero vector. Therefore, the eigenvalues of *$A$* satisfy:\n",
    "\n",
    "<center>*$det(A−λI)=0$*</center>\n",
    "\n",
    "The left-hand side above is a polynomial in *$λ$*\n",
    ", and is called the characteristic polynomial of *$A$*. Thus, to find the eigenvalues of *$A$* , we find the roots of the characteristic polynomial.\n",
    "\n",
    "Computationally, however, computing the characteristic polynomial and then solving for the roots is prohibitively expensive. Therefore, in practice, numerical methods are used - both to find eigenvalues and their corresponding eigenvectors. We won’t go into the specifics of the algorithms used to calculate eigenvalues, but here is a numpy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.+0.j  1.+0.j  1.+0.j]\n",
      " [ 2.+0.j  1.+0.j -0.+0.j]\n",
      " [ 3.+0.j  4.+0.j  5.+0.j]]\n",
      "[ 5.85410197+0.j -0.85410197+0.j  1.00000000+0.j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "A = np.array([[0,1,1],[2,1,0],[3,4,5]])\n",
    "\n",
    "u, V = la.eig(A)\n",
    "print(np.dot(V,np.dot(np.diag(u), la.inv(V))))\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Many matrices are **not** diagonizable, and many have *complex* eigenvalues (even if all entries are real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [-1  0]]\n",
      "[[ 0.+0.j  1.+0.j]\n",
      " [-1.+0.j  0.+0.j]]\n",
      "[ 0.+1.j  0.-1.j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "A = np.array([[0,1],[-1,0]])\n",
    "print(A)\n",
    "\n",
    "u, V = la.eig(A)\n",
    "print(np.dot(V,np.dot(np.diag(u), la.inv(V))))\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.8541+0.j -0.8541+0.j  1.0000+0.j]\n",
      "[ 5.8541 -0.8541  1.    ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "# If you know the eigenvalues must be real\n",
    "# because A is a positive definite (e.g. covariance) matrix\n",
    "# use real_if_close\n",
    "\n",
    "A = np.array([[0,1,1],[2,1,0],[3,4,5]])\n",
    "u, V = la.eig(A)\n",
    "print(u)\n",
    "print (np.real_if_close(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Values\n",
    "\n",
    "For any *$m×n$* matrix *$A$*, we define its singular values to be the square root of the eigenvalues of *$A$*<sup>*$T$*</sup>*$A$*. These are well-defined as *$A$*<sup>*$T$*</sup>*$A$* is always symmetric, positive-definite, so its eigenvalues are real and positive. Singular values are important properties of a matrix. Geometrically, a matrix *$A$* maps the unit sphere in *$ R$*<sup>*$n$*</sup> to an ellipse. The singular values are the lengths of the semi-axes.\n",
    "\n",
    "Singular values also provide a measure of the *stabilty* of a matrix. We’ll revisit this in the end of the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  QR decompositon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous decompositions, *$QR$* decomposition is a method to write a matrix *$A$*  as the product of two matrices of simpler form. In this case, we want:\n",
    "\n",
    "<center>*$A=QR$*</center>\n",
    "\n",
    "where *$Q$* is an *$m×n$* matrix with *$QQ$*<sup>*$T$*</sup>=*$I$* (i.e. *$Q$* is orthogonal) and *$R$* is an *$n×n$* upper-triangular matrix.\n",
    "\n",
    "This is really just the matrix form of the Gram-Schmidt orthogonalization of the columns of *$A$* . The G-S algorithm itself is unstable, so various other methods have been developed to compute the QR decomposition. We won’t cover those in detail as they are a bit beyond our scope.\n",
    "\n",
    "The first *$k$*  columns of *$Q$* are an orthonormal basis for the column space of the first *$k$* columns of *$A$* .\n",
    "\n",
    "Iterative QR decomposition is often used in the computation of eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important matrix decomposition is singular value decomposition or SVD. For any *$m×n$* matrix *$A$*, we may write:\n",
    "<center>*$A=UDV$*</center>\n",
    "\n",
    "where *$U$*\n",
    "is a unitary (orthogonal in the real case) *$m×m$* matrix, *$D$* is a rectangular, diagonal *$m×n$* matrix with diagonal entries *$d$*<sub>*$1$*</sub>,...,*$d$*<sub>*$m$*</sub> all non-negative. *$V$* is a unitary (orthogonal) *$n×n$* matrix. SVD is used in principle component analysis and in the computation of the Moore-Penrose pseudo-inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
